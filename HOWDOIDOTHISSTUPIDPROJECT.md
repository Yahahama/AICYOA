# HOWDOIDOTHISSTUPIDPROJECT
is a question I should have asked before trying to start it.

My first approach:

- AI is told that its only purpose in life is to fill in missing story
- AI recieves story node
- I tell AI to generate three comma seperated strings that represent choices based on that story node
- AI decides to keep generating story nodes and choices past that, even though I explicitly told it not to do that

This is clearly not working.

New approach idea:
- AI is told that it's a strong independent chatbot that has some sort of a personality
- AI recieves story node, in the template of a chatbot user messaging the chatbot
- AI hopefully creates three quoted choices seperated by commas
- The AI, with that chat history, is given a larger cap on tokens and is told to generate three followups in the same format
- AI does what it's supposed to and doesn't screw up

Update
  Using the 7b Hermes model (which unfortunately takes up 8 GB of RAM, but none of the smaller models were effective) I managed to get both three choices and three consequences in a single prompt. So far, it's worked consistently and given varying outpits, but weirdly for the opening scenario it always defaults to the exact same three choices while everything else changes. Good enough for now, though.

  Now, I need to get this flow as the end result:

  - User is asked in the terminal to input the number of layers deep to go for the CYOA, keeping in mind that the AI will be prompted 3^n times
  - User is asked what they want to call their JSON file
  - User is asked to type in what the opening scenario is (and informed that it'll use a default one if left blank)
  - AI takes forever to generate, but some form of progress is shown
  - JSON is created, which can be accessed through another python script that actually allows a playthrough of the (likely extremely incoherent) "story" generated by the AI
